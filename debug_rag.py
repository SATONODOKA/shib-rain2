#!/usr/bin/env python3
"""
RAGã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒãƒƒã‚°ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆèª­ã¿è¾¼ã¿ã¨æ¤œç´¢æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆã—ã¾ã™
"""

import os
import glob
import chromadb
from sentence_transformers import SentenceTransformer
import re
from typing import List, Dict, Any

# è¨­å®š
CHUNK_SIZE = 1000
CHUNK_OVERLAP = 200

def setup_embedding_model():
    """åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–"""
    try:
        print("ğŸ”„ åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ä¸­...")
        model = SentenceTransformer('intfloat/multilingual-e5-small')
        print("âœ… åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
        return model
    except Exception as e:
        print(f"âŒ åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—: {e}")
        return None

def setup_chroma_db():
    """ChromaDBã®åˆæœŸåŒ–"""
    try:
        print("ğŸ”„ ChromaDBã‚’åˆæœŸåŒ–ä¸­...")
        client = chromadb.PersistentClient(path="./chroma_db")
        
        try:
            collection = client.get_collection("sales_knowledge")
            count = collection.count()
            print(f"ğŸ“š æ—¢å­˜ã®ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼ˆ{count}ä»¶ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼‰")
        except:
            collection = client.create_collection(
                name="sales_knowledge",
                metadata={"description": "å–¶æ¥­ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹"}
            )
            print("ğŸ“š æ–°ã—ã„ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆã—ã¾ã—ãŸ")
            
        return client, collection
    except Exception as e:
        print(f"âŒ ChromaDBã®åˆæœŸåŒ–ã«å¤±æ•—: {e}")
        return None, None

def split_text(text: str, chunk_size: int = 1000, chunk_overlap: int = 200) -> List[str]:
    """ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²"""
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]+', text)
    
    chunks = []
    current_chunk = ""
    
    for sentence in sentences:
        sentence = sentence.strip()
        if not sentence:
            continue
            
        if len(current_chunk) + len(sentence) > chunk_size and current_chunk:
            chunks.append(current_chunk)
            overlap_text = current_chunk[-chunk_overlap:] if len(current_chunk) > chunk_overlap else current_chunk
            current_chunk = overlap_text + sentence
        else:
            current_chunk += sentence + "ã€‚"
    
    if current_chunk:
        chunks.append(current_chunk)
        
    return chunks

def load_documents(embedding_model, collection, document_path: str = "sample_documents"):
    """ã‚µãƒ³ãƒ—ãƒ«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®èª­ã¿è¾¼ã¿"""
    print(f"ğŸ”„ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ•ã‚©ãƒ«ãƒ€ã‚’ç¢ºèªä¸­: {document_path}")
    
    if not os.path.exists(document_path):
        print(f"âŒ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {document_path}")
        return False
        
    # å¯¾å¿œãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼
    file_patterns = ["*.md", "*.txt", "*.docx.md"]
    
    documents = []
    for pattern in file_patterns:
        files = glob.glob(os.path.join(document_path, pattern))
        documents.extend(files)
    
    if not documents:
        print("âš ï¸ èª­ã¿è¾¼ã¿å¯èƒ½ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False
        
    print(f"ğŸ“„ {len(documents)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹ã—ã¾ã—ãŸ")
    
    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å‡¦ç†
    processed_count = 0
    total_chunks = 0
    
    for i, file_path in enumerate(documents):
        try:
            print(f"ğŸ“– å‡¦ç†ä¸­ ({i+1}/{len(documents)}): {os.path.basename(file_path)}")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            if not content.strip():
                print(f"âš ï¸ ç©ºã®ãƒ•ã‚¡ã‚¤ãƒ«: {file_path}")
                continue
                
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰å‡ºå…¸æƒ…å ±ã‚’å–å¾—
            filename = os.path.basename(file_path)
            
            # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
            chunks = split_text(content, CHUNK_SIZE, CHUNK_OVERLAP)
            print(f"   ğŸ“ {len(chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²")
            
            # å„ãƒãƒ£ãƒ³ã‚¯ã‚’åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦DBã«ä¿å­˜
            for j, chunk in enumerate(chunks):
                chunk_id = f"{filename}#chunk-{j+1}"
                
                # åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã®è¨ˆç®—
                embedding = embedding_model.encode(chunk).tolist()
                
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
                metadata = {
                    "source": filename,
                    "chunk_id": chunk_id,
                    "chunk_index": j,
                    "file_path": file_path
                }
                
                # ChromaDBã«ä¿å­˜
                collection.add(
                    documents=[chunk],
                    embeddings=[embedding],
                    metadatas=[metadata],
                    ids=[chunk_id]
                )
            
            processed_count += 1
            total_chunks += len(chunks)
            
        except Exception as e:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼ ({file_path}): {e}")
    
    print(f"âœ… {processed_count}/{len(documents)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã¾ã—ãŸ")
    print(f"ğŸ“Š åˆè¨ˆ {total_chunks}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
    return processed_count > 0

def test_search(embedding_model, collection, query: str = "æ–°ä»»ç®¡ç†è·ç ”ä¿®ã®æ–™é‡‘"):
    """æ¤œç´¢ãƒ†ã‚¹ãƒˆ"""
    print(f"\nğŸ” æ¤œç´¢ãƒ†ã‚¹ãƒˆ: '{query}'")
    
    try:
        # ã‚¯ã‚¨ãƒªã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«åŒ–
        query_embedding = embedding_model.encode(query).tolist()
        
        # ChromaDBã§é¡ä¼¼æ¤œç´¢
        results = collection.query(
            query_embeddings=[query_embedding],
            n_results=3,
            include=["documents", "metadatas", "distances"]
        )
        
        print(f"ğŸ“‹ {len(results['documents'][0])}ä»¶ã®é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ç™ºè¦‹")
        
        for i in range(len(results["documents"][0])):
            content = results["documents"][0][i]
            metadata = results["metadatas"][0][i]
            distance = results["distances"][0][i]
            
            print(f"\n--- çµæœ {i+1} ---")
            print(f"å‡ºå…¸: {metadata['source']}")
            print(f"é¡ä¼¼åº¦: {1 - distance:.3f}")
            print(f"å†…å®¹: {content[:200]}...")
            
    except Exception as e:
        print(f"âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")

def main():
    print("ğŸš€ RAGã‚·ã‚¹ãƒ†ãƒ  ãƒ‡ãƒãƒƒã‚°ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 50)
    
    # 1. åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
    embedding_model = setup_embedding_model()
    if not embedding_model:
        return
    
    # 2. ChromaDBã®åˆæœŸåŒ–
    client, collection = setup_chroma_db()
    if not client or not collection:
        return
    
    # 3. ç¾åœ¨ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°ã‚’ç¢ºèª
    current_count = collection.count()
    print(f"ğŸ“Š ç¾åœ¨ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {current_count}")
    
    # 4. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒç©ºã®å ´åˆã¯èª­ã¿è¾¼ã¿
    if current_count == 0:
        print("\nğŸ”„ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆèª­ã¿è¾¼ã¿é–‹å§‹")
        success = load_documents(embedding_model, collection)
        if not success:
            print("âŒ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆèª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return
    else:
        print("ğŸ“š æ—¢å­˜ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¾ã™")
    
    # 5. æ¤œç´¢ãƒ†ã‚¹ãƒˆ
    test_queries = [
        "æ–°ä»»ç®¡ç†è·ç ”ä¿®ã®æ–™é‡‘",
        "ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Šæ§˜ã®èª²é¡Œ",
        "ç«¶åˆä»–ç¤¾ã¨ã®å·®åˆ¥åŒ–ãƒã‚¤ãƒ³ãƒˆ",
        "å»ºè¨­æ¥­ç•Œå‘ã‘ã®ç ”ä¿®å†…å®¹"
    ]
    
    for query in test_queries:
        test_search(embedding_model, collection, query)
    
    print("\nğŸ‰ ãƒ‡ãƒãƒƒã‚°ãƒ†ã‚¹ãƒˆå®Œäº†")

if __name__ == "__main__":
    main() 