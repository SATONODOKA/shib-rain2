#!/usr/bin/env python3
"""
LM Studio APIã‚µãƒ¼ãƒãƒ¼èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import subprocess
import time
import requests
import json
import os

def start_lm_studio_api():
    """LM Studioã®APIã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã™ã‚‹"""
    
    print("ğŸš€ LM Studio APIã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ä¸­...")
    
    # LM Studioã‚¢ãƒ—ãƒªã®ãƒ‘ã‚¹
    lm_studio_path = "/Applications/LM Studio.app"
    
    if not os.path.exists(lm_studio_path):
        print("âŒ LM Studioã‚¢ãƒ—ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False
    
    try:
        # LM Studioã‚’èµ·å‹•
        print("ğŸ“± LM Studioã‚¢ãƒ—ãƒªã‚’èµ·å‹•ä¸­...")
        subprocess.run(["open", "-a", "LM Studio"], check=True)
        
        # èµ·å‹•ã‚’å¾…ã¤
        print("â³ ã‚¢ãƒ—ãƒªã®èµ·å‹•ã‚’å¾…æ©Ÿä¸­...")
        time.sleep(10)
        
        # APIã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•ã‚’ç¢ºèª
        print("ğŸ” APIã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•ã‚’ç¢ºèªä¸­...")
        for i in range(30):  # æœ€å¤§30å›è©¦è¡Œ
            try:
                response = requests.get("http://localhost:1234/v1/models", timeout=2)
                if response.status_code == 200:
                    print("âœ… LM Studio APIã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¾ã—ãŸï¼")
                    
                    # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’è¡¨ç¤º
                    models = response.json()
                    if models.get("data"):
                        print("ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«:")
                        for model in models["data"]:
                            print(f"  - {model.get('id', 'unknown')}")
                    else:
                        print("âš ï¸ ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    
                    return True
                else:
                    print(f"âš ï¸ APIã‚µãƒ¼ãƒãƒ¼å¿œç­”: {response.status_code}")
            except requests.exceptions.ConnectionError:
                print(f"â³ æ¥ç¶šå¾…æ©Ÿä¸­... ({i+1}/30)")
            except Exception as e:
                print(f"âš ï¸ ã‚¨ãƒ©ãƒ¼: {e}")
            
            time.sleep(2)
        
        print("âŒ APIã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ")
        return False
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def check_api_status():
    """APIã‚µãƒ¼ãƒãƒ¼ã®çŠ¶æ…‹ã‚’ç¢ºèªã™ã‚‹"""
    try:
        response = requests.get("http://localhost:1234/v1/models", timeout=5)
        if response.status_code == 200:
            models = response.json()
            print("âœ… APIã‚µãƒ¼ãƒãƒ¼ã¯èµ·å‹•ä¸­ã§ã™")
            if models.get("data"):
                print("ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«:")
                for model in models["data"]:
                    print(f"  - {model.get('id', 'unknown')}")
            return True
        else:
            print(f"âŒ APIã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        return False

if __name__ == "__main__":
    print("=" * 50)
    print("LM Studio APIã‚µãƒ¼ãƒãƒ¼èµ·å‹•ãƒ„ãƒ¼ãƒ«")
    print("=" * 50)
    
    # ç¾åœ¨ã®çŠ¶æ…‹ã‚’ç¢ºèª
    print("\nğŸ” ç¾åœ¨ã®APIã‚µãƒ¼ãƒãƒ¼çŠ¶æ…‹ã‚’ç¢ºèªä¸­...")
    if check_api_status():
        print("âœ… æ—¢ã«èµ·å‹•ã—ã¦ã„ã¾ã™")
    else:
        print("âŒ èµ·å‹•ã—ã¦ã„ã¾ã›ã‚“")
        
        # èµ·å‹•ã‚’è©¦è¡Œ
        print("\nğŸš€ APIã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•ã‚’è©¦è¡Œä¸­...")
        if start_lm_studio_api():
            print("\nğŸ‰ èµ·å‹•å®Œäº†ï¼")
        else:
            print("\nâŒ èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ")
            print("\nğŸ“‹ æ‰‹å‹•ã§ã®è¨­å®šæ‰‹é †:")
            print("1. LM Studioã‚¢ãƒ—ãƒªã‚’é–‹ã")
            print("2. Local Serverã‚¿ãƒ–ã‚’ã‚¯ãƒªãƒƒã‚¯")
            print("3. Start Serverãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯")
            print("4. ãƒãƒ¼ãƒˆ1234ã§èµ·å‹•ã™ã‚‹ã“ã¨ã‚’ç¢ºèª")
    
    print("\n" + "=" * 50) 