# LM Studio 設定手順書

## 🚀 **LM Studio APIサーバーの起動手順**

### 1. LM Studioアプリの起動
- **Applicationsフォルダ**から「LM Studio」をダブルクリック
- または、ターミナルで `open -a "LM Studio"` を実行

### 2. モデルの読み込み
1. **My Models**タブをクリック
2. **gpt-oss-20b**モデルを探す
3. モデル名の横の**「Load」ボタン**をクリック
4. モデルの読み込みが完了するまで待つ（数分かかる場合があります）

### 3. APIサーバーの起動
1. **Local Server**タブをクリック
2. **Start Server**ボタンをクリック
3. 以下の情報が表示されることを確認：
   - **Port**: 1234
   - **Status**: Running
   - **API Key**: 設定されたキー（例：sk-1234567890abcdef）

### 4. 接続テスト
ターミナルで以下のコマンドを実行：
```bash
curl -s http://localhost:1234/v1/models
```

正常に接続されていれば、利用可能なモデルの一覧がJSON形式で表示されます。

## 🔧 **トラブルシューティング**

### APIサーバーが起動しない場合
1. **LM Studioを再起動**する
2. **ポート1234が他のアプリで使用されていない**ことを確認
3. **ファイアウォールの設定**を確認

### モデルが読み込めない場合
1. **モデルファイルが破損していない**ことを確認
2. **十分なメモリ**（16GB以上）があることを確認
3. **モデルの再ダウンロード**を試す

### 接続エラーが発生する場合
1. **LM Studioが起動している**ことを確認
2. **APIサーバーが起動している**ことを確認
3. **ポート番号が正しい**ことを確認

## 📊 **期待される動作**

### LM Studio接続前
- サイドバーに「❌ 未接続 - LM Studioを起動してください」と表示
- 質問に対する回答は検索結果のみ（フォールバック回答）
- システム詳細に「❌ 未接続」と表示

### LM Studio接続後
- サイドバーに「✅ 接続済み - 利用可能モデル: gpt-oss-20b」と表示
- 質問に対する回答はAI生成の詳細回答
- システム詳細に「✅ 接続済み」と表示

## 🎯 **次のステップ**

1. **LM Studioの設定完了**後、ブラウザで http://localhost:8501 にアクセス
2. **サイドバーの接続状況**を確認
3. **営業関連の質問**を入力してテスト
4. **AI回答の品質**を確認

## 📞 **サポート**

問題が解決しない場合は、以下を確認してください：
- LM Studioのバージョン
- 使用しているモデルの詳細
- エラーメッセージの内容
- システムのメモリ使用量 